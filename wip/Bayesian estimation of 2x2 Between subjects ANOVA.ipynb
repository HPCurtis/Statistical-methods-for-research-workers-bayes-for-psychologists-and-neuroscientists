{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import analysis packages\n",
    "%matplotlib inline\n",
    "import stan as ps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "from patsy import dmatrix\n",
    "from patsy.contrasts import Treatment, Sum\n",
    "\n",
    "# Importing nest_asyncio is only necessary to run pystan in Jupyter Notebooks.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML as Center\n",
    "\n",
    "Center(\"\"\" <style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style> \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps of Bayesian data analysis\n",
    "\n",
    "<font size = \"3\"> Kruschke (2015) offers a step by step formulation for how to conduct a Bayesian analysis:\n",
    "\n",
    "1. Identify the relevant data for the question under investigation.\n",
    "\n",
    "2. Define the descriptive (mathematical) model for the data.\n",
    "\n",
    "3. Specify the Priors for the model. If scientific research publication is the goal the priors will need to be accepted by a skeptical audience. This should be achievable using prior predictive checks to ascertain if the priors are reasonable.\n",
    "\n",
    "4. Using Bayes rule estimate the posterior for the parameters of the model using the likelihood and priors. Then use the posterior for conducting your inferences.\n",
    "\n",
    "5. Conduct model checks. i.e. Posterior predictive checks.</font> \n",
    "\n",
    "<font size = \"1\">This notebook will follow this approach generally.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Step 1 - Identify the relevant data for the question under investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study data/description\n",
    "\n",
    "The psychological literature suggests that both the physical distance and psychological factors can influence peoples' perceptions of distance. An example of this is the percieved distance to walk to a location when fed than when in a caloric deficit.\n",
    "\n",
    "The data analysed below is from Maglio and Polman (2014) study that investigated this general distance perception phenomenon. Specifically investigating, the effect of spatial orientation on percieved distance. This was achieved through the acqusition of 202 participants from the Toronto underground green trainline. Half of the passengers were headed eestbound and the other half westbound. The particpants were then further sub-divded indepently to give their pericieved distance from 4 different locations. For the analysis below two of these stations have been dropped for simplcicity of exposition and to demonstrate the most common experimental design in psychology the 2x2 with a Bayesian model equivalent to the 2x2 Between subjects ANOVA using prior contrasts in a linear model (Schad, Vasishth, Hohenstein and Kliegl, 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/ebrlab/Statistical-methods-for-research-workers-bayes-for-psychologists-and-neuroscientists/master/wip/Data/Maglio%20and%20Polman%202014.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Reduce the dataset to demonstrate 2x2 for simplicities sake\n",
    "dfReduced = df[df.station < 3]\n",
    "\n",
    "# Convert data variable into type 'category' for generating data\n",
    "dfReduced.direction = dfReduced.direction.astype('category') \n",
    "dfReduced.orientation = dfReduced.orientation.astype('category') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direction</th>\n",
       "      <th>orientation</th>\n",
       "      <th>station</th>\n",
       "      <th>subjective_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EAST</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EAST</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EAST</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAST</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EAST</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>WEST</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>WEST</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>WEST</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>WEST</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>WEST</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    direction orientation  station  subjective_distance\n",
       "0        EAST           1        1                    5\n",
       "1        EAST           1        1                    4\n",
       "2        EAST           1        1                    3\n",
       "3        EAST           1        1                    3\n",
       "4        EAST           1        1                    4\n",
       "..        ...         ...      ...                  ...\n",
       "97       WEST           2        2                    1\n",
       "98       WEST           2        2                    1\n",
       "99       WEST           2        2                    2\n",
       "100      WEST           2        2                    1\n",
       "101      WEST           2        2                    3\n",
       "\n",
       "[102 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfReduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder categories\n",
    "dfReduced['orientation'].cat.reorder_categories([2, 1], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TbTBA = \"\"\"\n",
    "data{\n",
    "\n",
    "int N; // Number of observations\n",
    "vector[N] y;\n",
    "int K; // Number of predictors\n",
    "matrix[N, K] X; // The design matrix\n",
    "\n",
    "}\n",
    "\n",
    "transformed data{\n",
    "real SD;\n",
    "real Mean = mean(y);\n",
    "SD = sd(y);\n",
    "}\n",
    "\n",
    "parameters{\n",
    "\n",
    "vector[K] beta;\n",
    "real<lower = 0> sigma;\n",
    "\n",
    "}\n",
    "\n",
    "model{\n",
    "\n",
    "// Priors\n",
    "beta[1] ~ normal(Mean, 2.5 * SD);\n",
    "beta[2:K] ~ normal(0, 10);\n",
    "sigma ~ normal(0, 10);\n",
    "\n",
    "// Likelihood\n",
    "y ~ normal(X * beta, sigma);\n",
    "}\n",
    "\n",
    "generated quantities{\n",
    "vector[K - 1] effect_sizes = beta[2:K]/sigma;\n",
    "\n",
    "real yrep[N];\n",
    "yrep = normal_rng(X * beta, sigma);\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate design matrix for the general linear model \n",
    "X = np.asarray(dmatrix(\"~ direction + orientation\", data = dfReduced))\n",
    "\n",
    "# Convert contrasts to effect coding\n",
    "X[:,1] = X[:,1] - .5\n",
    "X[:,2] = (X[:,2] - .5) \n",
    "\n",
    "# Generate the interaction term\n",
    "int_t = X[:,1] * X[:,2]\n",
    "\n",
    "# Add interaction term to the design matrix\n",
    "X =  np.c_[X, int_t]\n",
    "\n",
    "# Generate python dictionary \n",
    "data = {'N': len(dfReduced),\n",
    "        'y': dfReduced['subjective_distance'].values,\n",
    "         'X': X,\n",
    "         'K': np.shape(X)[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done."
     ]
    }
   ],
   "source": [
    "# Compile stan model into C++ code.\n",
    "sm = ps.build(TbTBA, data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling:   0%\n",
      "Sampling:   1% (100/8000)\n",
      "Sampling:   4% (300/8000)\n",
      "Sampling:  12% (1000/8000)\n",
      "Sampling:  18% (1400/8000)\n",
      "Sampling:  42% (3400/8000)\n",
      "Sampling:  68% (5400/8000)\n",
      "Sampling:  82% (6600/8000)\n",
      "Sampling: 100% (8000/8000)\n",
      "Sampling: 100% (8000/8000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 2.7e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.6e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 9e-06 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 1.3e-05 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.\n",
      "  Adjust your expectations accordingly!\n"
     ]
    }
   ],
   "source": [
    "fit = sm.sample(num_chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>2.528</td>\n",
       "      <td>1.927</td>\n",
       "      <td>-0.684</td>\n",
       "      <td>6.531</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.034</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[1]</th>\n",
       "      <td>-0.536</td>\n",
       "      <td>7.052</td>\n",
       "      <td>-13.461</td>\n",
       "      <td>13.178</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[2]</th>\n",
       "      <td>0.531</td>\n",
       "      <td>7.054</td>\n",
       "      <td>-13.482</td>\n",
       "      <td>13.097</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.147</td>\n",
       "      <td>1492.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[3]</th>\n",
       "      <td>-0.590</td>\n",
       "      <td>7.697</td>\n",
       "      <td>-13.512</td>\n",
       "      <td>15.217</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.147</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>1.104</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.968</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2221.0</td>\n",
       "      <td>2301.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect_sizes[0]</th>\n",
       "      <td>-0.498</td>\n",
       "      <td>6.426</td>\n",
       "      <td>-13.348</td>\n",
       "      <td>10.899</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.129</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>1353.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect_sizes[1]</th>\n",
       "      <td>0.473</td>\n",
       "      <td>6.426</td>\n",
       "      <td>-12.404</td>\n",
       "      <td>11.762</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.133</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect_sizes[2]</th>\n",
       "      <td>-0.547</td>\n",
       "      <td>7.011</td>\n",
       "      <td>-13.532</td>\n",
       "      <td>12.555</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.133</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "beta[0]          2.528  1.927  -0.684    6.531      0.045    0.034    1807.0   \n",
       "beta[1]         -0.536  7.052 -13.461   13.178      0.182    0.143    1495.0   \n",
       "beta[2]          0.531  7.054 -13.482   13.097      0.182    0.147    1492.0   \n",
       "beta[3]         -0.590  7.697 -13.512   15.217      0.181    0.147    1809.0   \n",
       "sigma            1.104  0.075   0.968    1.250      0.002    0.001    2221.0   \n",
       "effect_sizes[0] -0.498  6.426 -13.348   10.899      0.166    0.129    1502.0   \n",
       "effect_sizes[1]  0.473  6.426 -12.404   11.762      0.166    0.133    1503.0   \n",
       "effect_sizes[2] -0.547  7.011 -13.532   12.555      0.165    0.133    1815.0   \n",
       "\n",
       "                 ess_tail  r_hat  \n",
       "beta[0]            1999.0    1.0  \n",
       "beta[1]            1350.0    1.0  \n",
       "beta[2]            1346.0    1.0  \n",
       "beta[3]            1918.0    1.0  \n",
       "sigma              2301.0    1.0  \n",
       "effect_sizes[0]    1353.0    1.0  \n",
       "effect_sizes[1]    1387.0    1.0  \n",
       "effect_sizes[2]    1989.0    1.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(fit, var_names=['beta', 'sigma', 'effect_sizes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pystan fit object to IO for Arviz functions.\n",
    "idata = az.from_pystan(posterior=fit, posterior_model=sm, posterior_predictive=['yrep'],observed_data= 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior predicitve checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posterior simulated data sets for posterior predictive check\n",
    "az.plot_ppc(idata, data_pairs = {\"y\" : \"yrep\"}, num_pp_samples= 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the posterior predictive checks show above there is a quite dractic misfit of the model. What is happening here. The reason for such a poor fit is the the fact the data anlysed was ordinal. As such the normal likelihood used here and one of the assumptions in classical ANOVA's is inappropriate for such type of data. However the use of such inapproapriate models is common in the psychological sciences (Liddell & Kruscke, 2018). There are arguemetns in the literature that ANOVA can be robust in analysing  of Ordinal. The authors of this notebook make no counter arguments around this issue. We only direct readers to more appropriate and better fitting alternative generalised (ordinal) linear models  (Liddell & Kruscke, 2018), which we demonstrate in another notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\">As Kruschke (2015) correctly points out there is not standard formula or presentation method for reuslts in journal article like the APA guide for reporting frequentist analysis. It is likely there never will be, because as McElreath (2020) explains, Bayesian data analysis is more like a engineering approach to the problem and the resulting model that is fit will be analysis specific. In addition, as Gabry et al, (2019) argue visualisations maybe even more key. So, all the visualisations above would have to be included with any write up. Anyway, below the write up generally follows the advice of Kruschke (2015) chapter 25. In any application though it comes down to the problem to be described an the audience that needs to be convinced. </p><br/>\n",
    "\n",
    "<h2>Write up of categorical regression</h2><br/>\n",
    "\n",
    "Note having fitted the model and observed the ill fit it is likely that the following write would have little utility, given that the data is ordinal and a normal likelihood was inappropriate for this data analysis problem. Of course, throughout the scientific literatue their are countless examples of inappropriate models applied to data, McElreath (2020). Now, bearing that in mind, the following write up is still a useful example for how to write up a 2x2 design analysis using an Bayesian regression equivalent of factorial ANOVA.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/gold/cinn/misc/software/Ubuntu/20.04/envs/pystan_env/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dfReduced['direction_n'] = dfReduced['direction'].replace(['WEST', 'EAST'],\n",
    "                        [1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index variable with matrices parameterisation Stan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "matIndex = \"\"\"\n",
    "data{\n",
    "\n",
    "int N; // Number of observations\n",
    "vector[N] y; // Dependent variable\n",
    "int K; // Number of stations\n",
    "int J; // Number of orientations\n",
    "\n",
    "int<lower=1, upper = K> stations_id[N];\n",
    "int<lower=1, upper = J> orientations_id[N];\n",
    "}\n",
    "\n",
    "parameters{\n",
    "\n",
    "matrix[K,J] mu;\n",
    "real<lower = 0> sigma;\n",
    "\n",
    "}\n",
    "\n",
    "model{\n",
    "\n",
    "y ~ normal(mu[stations_id, orientations_id], sigma);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building: Semantic error:   -------------------------------------------------\n",
      "    20:  model{\n",
      "    21:  \n",
      "    22:  y ~ normal(mu[stations_id, orientations_id], sigma);\n",
      "         ^\n",
      "    23:  }\n",
      "   -------------------------------------------------\n",
      "\n",
      "Ill-typed arguments to '~' statement. No distribution 'normal' was found with the correct signature."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Semantic error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-352cd503aec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m               'orientations_id': dfReduced['direction_n'].values}\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mindex_sm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/storage/gold/cinn/misc/software/Ubuntu/20.04/envs/pystan_env/lib/python3.7/site-packages/stan/model.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(program_code, data, random_seed)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mreturn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/gold/cinn/misc/software/Ubuntu/20.04/envs/pystan_env/lib/python3.7/site-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(future, debug)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/gold/cinn/misc/software/Ubuntu/20.04/envs/pystan_env/lib/python3.7/site-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     69\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/gold/cinn/misc/software/Ubuntu/20.04/envs/pystan_env/lib/python3.7/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/gold/cinn/misc/software/Ubuntu/20.04/envs/pystan_env/lib/python3.7/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/gold/cinn/misc/software/Ubuntu/20.04/envs/pystan_env/lib/python3.7/site-packages/stan/model.py\u001b[0m in \u001b[0;36mgo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    487\u001b[0m                     \u001b[0mbuilding_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"<info>Building:</info> <error>{error_type}:</error>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                     \u001b[0mbuilding_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"<error>{exception_body_without_first_line}</error>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Semantic error"
     ]
    }
   ],
   "source": [
    "# Generate python dictionary \n",
    "index_data = {'N': len(dfReduced),\n",
    "              'y': dfReduced['subjective_distance'].values,\n",
    "              'K': len(np.unique(dfReduced['station'])),\n",
    "              'J': len(np.unique(dfReduced['orientation'])),\n",
    "              'stations_id': dfReduced['station'].values,\n",
    "              'orientations_id': dfReduced['direction_n'].values}\n",
    "\n",
    "index_sm = ps.build(matIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Liddell, T. M., & Kruschke, J. K. (2018). Analyzing ordinal data with metric models: What could possibly go wrong?. Journal of Experimental Social Psychology, 79, 328-348.\n",
    "\n",
    "Maglio, S. J., & Polman, E. (2014). Spatial orientation shrinks and expands psychological distance. Psychological Science, 25, 1345-1352.\n",
    "\n",
    "Schad, D. J., Vasishth, S., Hohenstein, S., & Kliegl, R. (2020). How to capitalize on a priori contrasts in linear (mixed) models: A tutorial. Journal of Memory and Language, 110, 104038."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
