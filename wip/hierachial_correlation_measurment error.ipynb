{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Step-2---define-the-descriptive-statistical-model\" data-toc-modified-id=\"Step-2---define-the-descriptive-statistical-model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Step 2 - define the descriptive statistical model</a></span><ul class=\"toc-item\"><li><span><a href=\"#\\begin{align*}--\n",
    "\\mu_\\theta-&amp;\\sim-Normal(0,-\\sigma_\\theta)-\n",
    "\\\\-\\mu_\\beta-&amp;\\sim-Normal(0,-\\sigma_\\beta)-\n",
    "\\\\-\\sigma_\\theta-&amp;\\sim-Normal(0,-b_{\\sigma\\theta})-\n",
    "\\\\-\\sigma_\\beta-&amp;\\sim-Normal(0,-b_{\\sigma\\beta})-\n",
    "\\\\-\\rho-&amp;\\sim-LKJ(1)-\n",
    "\\\\-\\eta_i-&amp;\\sim-MVN\\bigg((\\mu_\\theta,-\\mu_\\beta),-\\begin{bmatrix}-\\sigma_\\theta^2-&amp;\\rho\\sigma_\\theta\\sigma_\\beta-\n",
    "\\\\-\\rho\\sigma_\\theta\\sigma_\\beta-&amp;-\\sigma_\\beta^2-\n",
    "\\\\-\\end{bmatrix}\\bigg)-\n",
    "\\\\-\\hat{\\theta_i}-&amp;\\sim-Normal(\\eta_{1i,-\\sigma_{\\epsilon\\theta-i}})-\n",
    "\\\\-\\hat{\\beta_i}-&amp;\\sim-Normal(\\eta_{2i,-\\sigma_{\\epsilon\\beta-i}})\n",
    "\\end{align*}\" data-toc-modified-id=\"\\begin{align*}--\n",
    "\\mu_\\theta-&amp;\\sim-Normal(0,-\\sigma_\\theta)-\n",
    "\\\\-\\mu_\\beta-&amp;\\sim-Normal(0,-\\sigma_\\beta)-\n",
    "\\\\-\\sigma_\\theta-&amp;\\sim-Normal(0,-b_{\\sigma\\theta})-\n",
    "\\\\-\\sigma_\\beta-&amp;\\sim-Normal(0,-b_{\\sigma\\beta})-\n",
    "\\\\-\\rho-&amp;\\sim-LKJ(1)-\n",
    "\\\\-\\eta_i-&amp;\\sim-MVN\\bigg((\\mu_\\theta,-\\mu_\\beta),-\\begin{bmatrix}-\\sigma_\\theta^2-&amp;\\rho\\sigma_\\theta\\sigma_\\beta-\n",
    "\\\\-\\rho\\sigma_\\theta\\sigma_\\beta-&amp;-\\sigma_\\beta^2-\n",
    "\\\\-\\end{bmatrix}\\bigg)-\n",
    "\\\\-\\hat{\\theta_i}-&amp;\\sim-Normal(\\eta_{1i,-\\sigma_{\\epsilon\\theta-i}})-\n",
    "\\\\-\\hat{\\beta_i}-&amp;\\sim-Normal(\\eta_{2i,-\\sigma_{\\epsilon\\beta-i}})\n",
    "\\end{align*}-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><script type=\"math/tex; mode=display\" id=\"MathJax-Element-147\">\\begin{align*}  \n",
    "\\mu_\\theta &\\sim Normal(0, \\sigma_\\theta) \n",
    "\\\\ \\mu_\\beta &\\sim Normal(0, \\sigma_\\beta) \n",
    "\\\\ \\sigma_\\theta &\\sim Normal(0, b_{\\sigma\\theta}) \n",
    "\\\\ \\sigma_\\beta &\\sim Normal(0, b_{\\sigma\\beta}) \n",
    "\\\\ \\rho &\\sim LKJ(1) \n",
    "\\\\ \\eta_i &\\sim MVN\\bigg((\\mu_\\theta, \\mu_\\beta), \\begin{bmatrix} \\sigma_\\theta^2 &\\rho\\sigma_\\theta\\sigma_\\beta \n",
    "\\\\ \\rho\\sigma_\\theta\\sigma_\\beta & \\sigma_\\beta^2 \n",
    "\\\\ \\end{bmatrix}\\bigg) \n",
    "\\\\ \\hat{\\theta_i} &\\sim Normal(\\eta_{1i, \\sigma_{\\epsilon\\theta i}}) \n",
    "\\\\ \\hat{\\beta_i} &\\sim Normal(\\eta_{2i, \\sigma_{\\epsilon\\beta i}})\n",
    "\\end{align*}</script></a></span></li></ul></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import analysis packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stan as ps\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from patsy import dmatrix\n",
    "import arviz as az\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing nest_asyncio is only necessary to run pystan in Jupyter Notebooks.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurement error models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data\n",
    "\n",
    "The following data below is the example data distrbuted for the Matske et al (2017) from this Open science foundation https://osf.io/mvz29/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from directory exported from RData file from origninal Win BUGS example\n",
    "observed = 'https://raw.githubusercontent.com/ebrlab/Statistical-methods-for-research-workers-bayes-for-psychologists-and-neuroscientists/master/wip/Data/observed.csv'\n",
    "epsilon = 'https://raw.githubusercontent.com/ebrlab/Statistical-methods-for-research-workers-bayes-for-psychologists-and-neuroscientists/master/wip/Data/epsilon.csv'\n",
    "\n",
    "df1 = pd.read_csv(observed)\n",
    "df2 = pd.read_csv(epsilon)\n",
    "\n",
    "y = np.asarray(dmatrix(\"0 + theta + beta\", data = df1) )\n",
    "epsilon = np.asarray(dmatrix(\"0 + theta_epsilon + beta_epsilon\", data = df2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - define the descriptive statistical model  \n",
    "\n",
    "\n",
    "## \\begin{align*}  \n",
    "\\mu_\\theta &\\sim Normal(0, \\sigma_\\theta) \n",
    "\\\\ \\mu_\\beta &\\sim Normal(0, \\sigma_\\beta) \n",
    "\\\\ \\sigma_\\theta &\\sim Normal(0, b_{\\sigma\\theta}) \n",
    "\\\\ \\sigma_\\beta &\\sim Normal(0, b_{\\sigma\\beta}) \n",
    "\\\\ \\rho &\\sim LKJ(1) \n",
    "\\\\ \\eta_i &\\sim MVN\\bigg((\\mu_\\theta, \\mu_\\beta), \\begin{bmatrix} \\sigma_\\theta^2 &\\rho\\sigma_\\theta\\sigma_\\beta \n",
    "\\\\ \\rho\\sigma_\\theta\\sigma_\\beta & \\sigma_\\beta^2 \n",
    "\\\\ \\end{bmatrix}\\bigg) \n",
    "\\\\ \\hat{\\theta_i} &\\sim Normal(\\eta_{1i, \\sigma_{\\epsilon\\theta i}}) \n",
    "\\\\ \\hat{\\beta_i} &\\sim Normal(\\eta_{2i, \\sigma_{\\epsilon\\beta i}})\n",
    "\\end{align*}\n",
    "\n",
    "Lets break down this hierchial model for correltion estimation in  the presence of measurment error for as described Matske et al.(2017) with the generla methods that origninally proposed by Behesta et al (2009). The model can be genrally broken down into two levels. The first of which is the level of the observed data which it he formulation above are $            (\\hat{\\theta_i}, \\hat{\\beta_i} )$ with the corresponding observe error $\\sigma_{\\epsilon\\beta i}, \\sigma_{\\epsilon\\beta i}$ for each observation $ i,$ $i = 1...N$\n",
    "\n",
    "$\\sigma_{\\epsilon\\beta i}, \\sigma_{\\epsilon\\beta i}$ can be either assumed known or estimated from data. Of note this model does not assume homogeneity of variance, because each observation $i$ has it own associated error.\n",
    "\n",
    "The second level is the level of all the inferfered varibles (parameters) of the model. for each observation $i$ a $\\eta$ is estimated with $\\eta = (\\theta_i, \\beta_i)$ whicha re the infered true values once error is accounted for in the model. $\\rho$ is the correlation parameter between $(\\theta, \\beta)$ when measument error has been modelled. $(\\mu_{\\theta}, \\mu_{\\beta}, \\sigma_{\\theta}, \\sigma_{\\beta}, \\rho)$ are estimated from the data and thus have priors associated with them. This where the model use here diverges from  the WinBugs implementation from Matske et al. (2007). Wihtin this implemetation or the parameter have given weaklyinformative prior values using normal disributions, wheras the Matske etal implemtation suggested very broad priors and to use uniform distributions on the $\\sigma$. Final difference is with the $\\rho$ prior. orignally a uniform(-1,1) is suggested following Jeffrey (1961), but Stan implemetns LKJ priors which can have same effect as uniform(-1,1) if the set to value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'n': len(y),\n",
    "'J': 2,\n",
    "'y': y,\n",
    "'epsilon': epsilon,\n",
    "'sigma_sigma_theta': 5,\n",
    "'sigma_sigma_beta': 5,\n",
    "'sigma_mu_theta': 5,\n",
    "'sigma_mu_beta': 5,\n",
    "'cor_val': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier = \"\"\"\n",
    "data {\n",
    "// Stan ver of \"Bayesian Inference for Correlations in the Presence of Measurement Error and Estimation Uncertainty\"\n",
    "// WinBugs model\n",
    "\n",
    "int<lower = 1> n; // Number of observations\n",
    "int<lower = 1> J; // Number of groups\n",
    "\n",
    "// Wide format data array containing \n",
    "// theta and beta observed values\n",
    "vector[J] y[n];\n",
    "vector[J] epsilon[n];\n",
    "\n",
    "// Prior values must be integer as that is how ther sepcified in python\n",
    "// to use real number these would need changing\n",
    "int sigma_mu_theta;\n",
    "int sigma_mu_beta;\n",
    "int sigma_sigma_theta;\n",
    "int sigma_sigma_beta;\n",
    "int cor_val;\n",
    "}\n",
    "parameters {\n",
    "  vector[J] mu;\n",
    "  vector<lower = 0>[J] sigma;   \n",
    "  vector[J] z[n];\n",
    "  cholesky_factor_corr[J] rho;\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "\n",
    " vector[J] eta[n];\n",
    " matrix[J, J] L = diag_pre_multiply(sigma, rho);\n",
    " for (i in 1:n){\n",
    "  eta[i] = mu + L * z[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "model{\n",
    "\n",
    "//Priors\n",
    "// Hyperpriors\n",
    "mu ~ normal(0, sigma_mu_theta);\n",
    "\n",
    "sigma ~ normal(0, sigma_sigma_theta);\n",
    "\n",
    "\n",
    "rho ~ lkj_corr_cholesky(cor_val);\n",
    "\n",
    "for(i in 1:n) {\n",
    "    z[i] ~ std_normal();\n",
    "  }\n",
    "\n",
    "// likelihood\n",
    "for (i in 1:n){\n",
    "        y[i,] ~ normal(eta[i,], epsilon[i, ]);  \n",
    "    }\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "\n",
    "  corr_matrix[J] rho_u = rho * rho';\n",
    "  \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 61.1s, done."
     ]
    }
   ],
   "source": [
    "sm1 = ps.build(hier, data=data, random_seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Using hmc_nuts_diag_e_adapt to sample the model whilst specfing \n",
    "#the step size of sampler to .95 to remove the divergent transitions.\n",
    "fit = sm1.hmc_nuts_diag_e_adapt(num_chains=4, stepsize = .95)\n",
    "fit_df = fit.to_frame()\n",
    "az.summary(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traceplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7d40725aa713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sigma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "az.plot_trace(fit, var_names=['sigma']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(fit, var_names=['mu']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(fit['rho_u'][0,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No systematic pathologies with MCMC chains and generally follow a \"Fuzzy caterpillar\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etal1 = []\n",
    "etal2 = []\n",
    "for i in np.arange(len(df1)):\n",
    "    eta1 = np.mean(fit['eta'][i,0])\n",
    "    eta2 = np.mean(fit['eta'][i,1])\n",
    "    etal1.append(eta1)\n",
    "    etal2.append(eta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot showing the shrinkage effect from observed to infered true estimates\n",
    "# after estiamting the correltion whilst accouting for the measurment errors of observed \n",
    "#values\n",
    "\n",
    "# x coordiantes for vertical lines\n",
    "xcoords = [pearsonr(df1['theta'], df1['beta'])[0], np.mean(fit['rho_u'][0,1])]\n",
    "col = ('y', 'r')\n",
    "legend = ['True', 'Observed']\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "sns.scatterplot(ax= ax1,x = etal1, y = etal2);\n",
    "sns.scatterplot(ax= ax1,x = df1['theta'], y = df1['beta']);\n",
    "ax1.legend(['True', 'Observed'])\n",
    "\n",
    "sns.kdeplot(fit['rho_u'][0,1], ax= ax2);\n",
    "plt.xlabel('Correlation')\n",
    "\n",
    "# for i in range(2):\n",
    "plt.axvline(xcoords[0],color= col[0]);\n",
    "plt.axvline(xcoords[1], color= col[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Behseta, S., Berdyyeva, T., Olson, C. R., & Kass, R. E. (2009). Bayesian correction for attenuation of correlation in multi-trial spike count data. Journal of neurophysiology, 101(4), 2186-2193.\n",
    "\n",
    "Matzke, D., Ly, A., Selker, R., Weeda, W. D., Scheibehenne, B., Lee, M. D., ... & Bouwmeester, S. (2017). Bayesian inference for correlations in the presence of measurement error and estimation uncertainty. Collabra: Psychology, 3(1)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.319px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
